model_name: 'meta-llama/Llama-3.2-1B-Instruct'
# model_name: 'meta-llama/Llama-3.2-1B'

tokenizer_config:
  use_fast: false

num_proc: 10

max_shard_size: '100MB'